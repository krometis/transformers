{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccedab87-250d-4ba8-8e5c-4f9b0918fc48",
   "metadata": {},
   "source": [
    "# Explore Third-Party Models\n",
    "Since we don't have time to train a transformer, this notebook is designed to allow users to explore models trained by third parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2dc946-f0db-4433-bc31-c92a4af330ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn.functional as F\n",
    "from transformers import pipeline\n",
    "\n",
    "from bertviz import head_view, neuron_view, model_view\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef81f83-361b-4cdd-a010-ed2d2917f4cf",
   "metadata": {},
   "source": [
    "## GPT-2\n",
    "An early predecessor to GPT-3.5, which took the world by storm with the release of ChatGPT in 2022.\n",
    "\n",
    "References:\n",
    "- Radford, Alec, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language Models Are Unsupervised Multitask Learners. February 14, 2019. https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf\n",
    "- Original blog post: https://openai.com/index/better-language-models/\n",
    "- https://en.wikipedia.org/wiki/GPT-2\n",
    "- https://github.com/openai/gpt-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc29c7-d008-476b-a265-d8fcbc5b274c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054a7a19-ed86-4a88-85d1-045b89f88a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load model\n",
    "model_id = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_id)\n",
    "model = GPT2Model.from_pretrained(model_id, output_attentions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd43bdd-7167-4477-8c22-8e655ac204d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5fd0e6-b849-4e3d-9ef4-f69187e02095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prepare input (keep the sentence relatively short or the visualizations below might become slow)\n",
    "sentence = \"The robot must obey the orders given it by human beings.\"\n",
    "inputs = tokenizer.encode(sentence, return_tensors='pt')\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b18e5b-39e0-477c-be79-2ea4a8ddb5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get attention weights\n",
    "outputs = model(inputs)\n",
    "attentions = outputs.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66f4e5-9367-45a8-b48b-9d87ae924c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#interactive visualization (requires, e.g., jupyter)\n",
    "head_view(attentions, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ead9d0-feda-4ca0-89ce-ae03181a4185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#alternative, non-interactive visualization\n",
    "layer =  0 #depth (valid range: 0 to 11)\n",
    "head  =  0 #width (valid range: 0 to 5)\n",
    "attention_matrix = attentions[layer][0, head].detach().numpy()\n",
    "\n",
    "clean_tokens = [t.replace('Ġ', ' ') for t in tokens] #replace funky character representing space\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(attention_matrix, xticklabels=clean_tokens, yticklabels=clean_tokens, cmap='viridis')\n",
    "plt.title(f\"Attention Heatmap: Layer {layer}, Head {head}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24b43a-d148-425f-b98f-acfc577a974c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#interactive visualization (requires, e.g., jupyter)\n",
    "model_view(attentions, tokens, display_mode=\"light\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa6aba-24bb-49fa-af4b-0596feef4fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this is a very cool visualization of attetion and the queries and keys that make it up\n",
    "#however, it can take some time to run\n",
    "from bertviz.transformers_neuron_view import GPT2Model, GPT2Tokenizer\n",
    "model_type = 'gpt2'\n",
    "model_version = 'gpt2'\n",
    "model     = GPT2Model.from_pretrained(model_version)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_version)\n",
    "neuron_view.show(model, model_type, tokenizer, sentence, display_mode='dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c187ad4c-d2f0-4f61-ba39-a6b5fa7fc7b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae8271-2231-456d-9f9d-dee44980c437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the text generation pipeline\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Generate text\n",
    "prompt = \"The data scientist decided to\"\n",
    "results = generator(prompt, num_return_sequences=1)\n",
    "\n",
    "print(results[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a7aeb-88b2-481f-8b9f-b26ad9e7ab9a",
   "metadata": {},
   "source": [
    "### Look at prediction probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2c077-dff8-4ce7-a31c-1ca492b02a63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load model and tokenizer (slightly different signature from before)\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380a761-12f2-416d-9b2e-3995fc68255d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenize input\n",
    "prompt = \"The data scientist decided to take his data and\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c07b681-b852-4ae8-938b-1e308c42a708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get model output (logits)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    #get logits for the last token in the sequence\n",
    "    next_token_logits = outputs.logits[0, -1, :]\n",
    "\n",
    "#convert Logits to probabilities using softmax\n",
    "probs = F.softmax(next_token_logits, dim=-1)\n",
    "\n",
    "#get the top n candidates\n",
    "n = 5\n",
    "top_n = torch.topk(probs, n)\n",
    "\n",
    "print(f\"Prompt: {prompt}\\n\")\n",
    "print(f\"{'Token':<15} | {'Probability':<10}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for score, token_id in zip(top_n.values, top_n.indices):\n",
    "    token_str = tokenizer.decode([token_id])\n",
    "    print(f\"{token_str:<15} | {score.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabffc95-83ae-4efb-97d1-6420165a574e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BERT\n",
    "A foundational transformer-based natural language processing modeling released by Google researchers in 2018.\n",
    "\n",
    "See:\n",
    "- Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. “BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding.” arXiv.Org, October 11, 2018. https://arxiv.org/abs/1810.04805v2.\n",
    "- https://en.wikipedia.org/wiki/BERT_(language_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac036ea-943e-469a-992b-4a5bf8395ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead0093-f8e4-45ae-84e4-23e4e5538a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load model and tokenizer\n",
    "#use output_attentions=True to ensure the model returns the weights\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, output_attentions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec968be-96be-4a61-9cb8-b1effb615cfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be973071-1958-4558-8a99-c702739e28f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenization\n",
    "sentence = \"The cat sat on the mat because it was comfortable.\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d6872-adfe-4b3a-a011-620c1d2bcdf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#compute attention\n",
    "#model returns a tuple: (last_hidden_state, pooler_output, attentions)\n",
    "outputs = model(**inputs)\n",
    "attentions = outputs.attentions  # This is a list of 12 tensors (one per layer)\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a849081-e0a7-4bb2-86c0-3c315447d0fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#interactive visualization (requires, e.g., jupyter)\n",
    "head_view(attentions, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7792296c-b560-48e5-aa3c-82168fb4ba54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#alternative, non-interactive visualization\n",
    "layer =  0 #depth (valid range: 0 to 11)\n",
    "head  =  0 #width (valid range: 0 to 5)\n",
    "attention_matrix = attentions[layer][0, head].detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(attention_matrix, xticklabels=tokens, yticklabels=tokens, cmap='viridis')\n",
    "plt.title(f\"Attention Heatmap: Layer {layer}, Head {head}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcdbf63-9ea0-4214-b38b-4f273f7b1999",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Make predictions\n",
    "BERT is not an auto-regressive model - it looks forwards and backwards - so we need to indicate where to make a prediction with `[MASK]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd3586-a580-4fec-855a-94467de5c3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 1. Initialize the Fill-Mask pipeline\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "# 2. Define a sentence with a [MASK] token\n",
    "text = \"The data scientist visualized his data using [MASK].\"\n",
    "\n",
    "# 3. Get predictions\n",
    "results = fill_mask(text)\n",
    "\n",
    "# 4. Display the top 5 candidates\n",
    "for res in results:\n",
    "    print(f\"Score: {res['score']:.4f} | Word: {res['token_str']} | Sentence: {res['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d46bb55-b544-47bd-93fa-0b83c1aeb3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Transformers)",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
